{"pageProps":{"body":{"cells":[{"cell_type":"markdown","metadata":{},"source":["(Référence des formules: Bibm@th)\n","# **Les variables aléatoires** \n","$\\hspace{1cm}$\n","\n","## **1. Variables aléatoires discrètes :**\n","Une variable aléatoire discrète est une application $X$ de $\\Omega$ (Univers, contenant toutes les possibilités) dans $E$ tel que $X(\\Omega)$ soit fini ou dénombrable.\n","- Notons : $X(\\Omega) = \\{x_n; n \\in I\\}$ où $I$ est fini ou dénombrable.\n","- La loi de probabilité de $X$, soit $(P_n)_{n \\; \\in \\; I}$, est noté : $P_n =P(X=x_n)$.\n","\n","**Note**: Un ensemble dénombrable est un ensemble en bijection avec l'ensemble des entiers $\\mathbb{N}$ (équipotent).\n","\n","- La probabilité $P(y|x)$ est la probabilité conditionnelle de $y$ sachant $x$ (Probabilité d'un évenement sachant qu'un autre évenement a eu lieu), et est définit comme suit :\n","$$P(Y = y|X = x) = \\frac{P(X = x, Y = y)}{P(X = x)}$$\n","où $P(X = x, Y = y)$ est l'application de la **loi conjointe** sur les variables $X$ et $Y$. \n","- La loi conjointe entre deux variables $X$ et $Y$ est la loi qui définit toutes les probabilités du vecteur $(X, Y)$ dans un ensemble $\\mathbb{E}^2$, en d'autres termes, la probabilité de l'apparition de $X$ et $Y$ en même temps $P((X = x) \\cap (Y = y))$ (à ne pas confondre avec la probabilité conditionnelle) :\n","$$P_{X,Y}(I \\times J) = P(X \\in I \\; \\; et \\; \\; Y \\in J)$$  \n","***Exemple***: Soit $E$ un évenement où on tire 2 valeurs dans l'univers $\\{-1, 1\\}^2$. $X$ est la somme des deux valeurs et $Y$ leur produit. On aura alors $X \\in \\{-2, 0, 2\\}$ et $Y \\in \\{-1, 1\\}$. Voici les valeurs possible de la loi conjointe entre $X$ et $Y$ :\n","$$P(X = -2, Y = -1) = 0, \\;\\;\\;\\; P(X = 0, Y = -1) = \\frac{1}{2}$$\n","$$P(X = 2, Y = -1) = 0, \\;\\;\\;\\; P(X = -2, Y = 1) = \\frac{1}{4}$$\n","$$P(X = 0, Y = 1) = 0, \\;\\;\\;\\; P(X = 2, Y = 1) = \\frac{1}{4}$$  \n","**Note**: faites attention à l'ordre des variables dans la loi conjointe.  \n","**Note**: Si $P(X = x, Y = y)$ est appellé loi conjointe, alors $P(X = x), P(Y = y)$ sont appellées **lois marginales**.  \n","- Il possible de retrouver les lois marginales à partir de la loi conjointe en fixant la valeur d'une variable $X \\in \\{x_1, ..., x_p\\}$ ou $Y \\in \\{y_1, ..., y_q\\}$:\n","$$P(X = x_i) = \\sum_{j=1}^q P(X = x_i, Y = y_j) \\;\\; et \\;\\; P(Y = y_j) = \\sum_{i=1}^p P(X = x_i, Y = y_j)$$ \n","- Cependant l'inverse n'est pas toujours correcte, il est possible de trouver la loi conjointe entre deux variables seulement si ces dérnières sont indépendentes, et dans ce cas là on aura :\n","$$P(X = x, Y = y) = P(X=x)P(Y=y)$$  \n","Si les deux variables ne sont pas indépentes alors il faudra plus d'informations sur le rapport entre $X$ et $Y$ :\n","$$P(X = x, Y= y) = P(X = x)P(Y = y | X = x) \\;\\; (origine \\;\\; de \\;\\; la \\;\\; loi \\;\\; conditionnelle)$$\n","\n","**I. Espérence d'une variable aléatoire discrète:** notée $\\mathbb{E}[X]$, est la valeur moyenne qu'on s'attend à trouver pour la variable aléatoire $X$. La formule de l'espérence est définit comme suit :\n","$$\\mathbb{E}(X) = \\sum_{n \\in I} x_n P(X = x_n)$$\n","**II. Variance d'une variable aléatoire discrète:** notée $V[X]$, la mesure de dispersion des valeurs de $X$. Elle est définit comme suit :\n","$$V[X] = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$$\n","- *Démonstration* de $V[X] \\Longrightarrow$ :  \n","$= \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2 - 2X\\mathbb{E}[X] + \\mathbb{E}[X]^2]$  \n","$= \\mathbb{E}[X^2] - 2\\mathbb{E}[X]\\mathbb{E}[X] + \\mathbb{E}[X]^2 = \\mathbb{E}[X^2] - 2\\mathbb{E}[X]^2 + \\mathbb{E}[X]^2$  \n","$= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$   \n","**Note** $\\mathbb{E}[\\mathbb{E}[X]] = \\mathbb{E}[X]$  \n","\n","## **2. Variables aléatoires continue (Variables à densité):**\n","Une variable aléatoire continue est une fonction $X$ de $\\Omega$ dans $\\mathbb{R}$ $(X:\\Omega \\rightarrow \\mathbb{R})$ telle qu'il existe $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ continue par morceaux et vérifiant :\n","$$\\forall a < b : P(X \\in [a, b]) = \\int_a^b f(x)dx$$\n","- Si une telle fonction existe, elle est alors appellé densité de la variable aléatoire $X$. Cette fonction doit nécéssairement être positive et vérifie $\\int_{- \\infty}^{+ \\infty} f(x)dx = 1$ (l'air de la fonction $f$ correspond à une probabilité, et la somme des probabilités de tout les évenements $x_n$ dans $\\mathbb{R}$ doit être égale à 1).\n","- On pose alors la loi suivante :\n","$$f(x) = \\frac{dF(x)}{dx}$$\n","où $F(x)$ est la fonction de répartition de la variable. \n","- Toutes variables continue est définit par une certaine fonction de répartition, et en intégrant cette dérinère on obtient la fonction de densité.\n","\n","**1. Espérence d'une variable aléatoire continue**: de la même manière que pour les variables discrètes, sauf qu'on utilise une intégrale étant donné la continuité de la fonction :\n","$$\\mathbb{E}[X] = \\int_{-\\infty}^{+\\infty} xf(x)dx$$\n","**2. Variance d'une variable aléatoire continue** même formule : $V[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$\n","\n","## **3. Fonctions de répartition les plus connues :**\n","#### **1. Loi géométrique :**\n","Une variable aléatoire discrète $X$ suit une loi géométrique de paramètres $p$, qu'on note $X \\sim \\mathcal{G}(p)$ si :\n","- $X(\\Omega) = \\mathbb{N}^{*}$\n","- $P(X = k) = p(1 - p)^{k - 1} = pq^{k - 1}$  \n","\n","$X$ admet alors une espérence et une variance :\n","- $\\mathbb{E}[X] = \\frac{1}{p}$  \n","- $V[X] = \\frac{q}{p^2} = \\frac{1 - p}{p^2}$ \n","\n","**Exemple**: Lancer de pièce de monnaie truquée avec les probabilités $P(pile) = 0.1$ et $P(face) = 1 - p = 0.9$. soit $X$ le nombre de lancers pour obtenir pile pour la première fois, $X$ suit alors une loi géométrique. Dans cet exemple, le paramètre $k$ est le nombre de lancers total.  \n","Pour $k = 5$ (5 lancers), la probabilité d'avoir pile pour la première fois est $pqqqq = pq^4$. L'espérence dans ce cas est le nombre moyen de lancers pour avoir pile, avec $p = 0.1$ on obtient $\\mathbb{E}[X] = \\frac{1}{0.1} = 10$ lancers en moyenne. \n","\n","La loi géométrique est souvent utilisée pour déterminer la durée de vie d'un phénomène (par exemple, durée de vie d'une ampoule).\n","\n","#### **2. Loi de Poisson :**\n","Soit $\\lambda > 0$. Une variable aléatoir discrète $X$ suit une loi de Poisson de paramètre $\\lambda$ et noté $X \\sim \\mathcal{P}(\\lambda)$ si :\n","- $X(\\Omega) = \\mathbb{N}$\n","- $P(X = k) = e^{-\\lambda}\\frac{\\lambda^{k}}{k!}$\n","\n","$X$ admet alors une espérence et une variance :\n","- $\\mathbb{E}[X] = \\lambda$\n","- $V[X] = \\lambda$\n","\n","*Note* la loi de Poisson est la loi des phénomènes rares et des petites probabilités, généralement utilisée pour modéliser des systèmes de file d'attente. Pour plus d'informations, consulter ce [lien](https://fr.wikipedia.org/wiki/Loi_de_Poisson).\n","\n","#### **3.Loi exponentielle :**\n","$X$ est une variable aléatoire continue suivant la loi exponentielle de paramètre $a > 0$, note $X \\sim \\mathcal{e}(a)$ si elle est absolument continue et admet pour densité :\n","- $f(x) = x =\\begin{cases}ae^{-ax} & si \\;\\; x > 0\\\\0 & sinon\\end{cases}$  \n","\n","$X$ admet une espérence et une variance :\n","- $\\mathbb{E}[X] = \\frac{1}{a}$\n","- $V[X] = \\frac{1}{a^2}$\n","\n","*Note* la loi exponentielle est la version continue de la loi géométrique; Sert souvent à modéliser la durée de vie d'une entité. $X$ dans ce cas là est une variable continue sans mémoire, et elle vérifie donc :$\\forall x, y \\geq 0$ : $P(X \\geq x+y |X \\geq y) = P(X \\geq x)$ (car on traite généralement des périodes de temps avec la loi exponentielle).  \n","\n","La répartition de $X$ est : $F(t) = \\begin{cases}0 & si \\;\\; t \\leq 0\\\\ 1 - e^{-at} & sinon \\end{cases}$  \n","Je note bien $t$ et non pas $x$ car l'unité est le temps.\n","\n","#### **4. Loi uniforme :**\n","$X$ est une variable aléatoire continue répartit de manière uniforme sur un ensemble $[a, b]$, noté $X \\sim \\mathcal{U}(a, b)$ si elle admet comme fonction de densité :\n","- $f(x) = \\begin{cases} \\frac{1}{b - a} & x \\in [a, b]\\\\0 & sinon \\end{cases}$  \n","\n","et la fonction de répartition de $X$ est alors :\n","- $F(x) = \\begin{cases} 0 & si \\;\\; t \\leq x \\\\ \\frac{x - a}{b - a} & si \\;\\; x \\in [a, b] \\\\ 1 & sinon\\end{cases}$\n","\n","On donne aussi : $\\mathbb{E}[X] = \\frac{a+b}{2}$ et $V[X] = \\frac{(b-a)^2}{12}$.\n","\n","#### **5. Loi normale (ou Gaussienne) :** (Important pour le machine learning :D)\n","$X$ est une variable aléatoire continue dont la réparition est normale (ou Gaussienne) avec les paramètres $m$ (espérence) et $\\sigma^2$ (variance), et que l'on note $X \\sim \\mathcal{N}(m, \\sigma^2)$, si elle est continue et a pour densité :\n","- $f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}exp(-\\frac{(x - m)^2}{2\\sigma^2})$\n","\n","On aura alors $\\mathbb{E}(X) = m$ et $V[X] = \\sigma^2$\n","\n","## **Connaissance transversales en probabilités :**\n","### **1. Système d'événement complet :**\n","Soit $(\\Omega, A, P)$ un espace probabiliste. Un système complet d'événement est un systèmes où tout les événements réunis forment $\\Omega$. donc :\n","- $i \\neq j \\Longrightarrow A_i \\cup A_j = \\emptyset$;   (événemenents indépendants).\n","- $\\bigcup_{i \\in I} A_i = \\Omega$\n","\n","On parle aussi de système quasi-complet quand la deuxième condition est remplacée par $\\sum_{i \\in I} P(A_i) = 1$.\n","\n","### **2. Expérience ou schéma de Bernoulli :**\n","Une expérience de Bernoulli n'a que deux issues possibles, succès ($s$) ou échec ($\\overline{s}$).\n","Le succès est définit par une probabilité $p$ et l'échec par une probabilité $q = 1 - p$.\n","Le paramètre de l'expérience est $p$, la probabilité d'un succès.  \n","**Exemple**: Pour un lancer de dé, la probabilité d'avoir un 6, étant le succès, est définit par $p = \\frac{1}{6}$.  \n","$X$ est une variable aléatoire qui est définit par $X=1$ en cas de réussite et $X=0$ en cas d'échec. $X$ suit alors une loi de Bernoulli de paramètre $p$ noté $X \\sim \\mathcal{B}(p)$.  \n","$X$ admet une espérence et une variance :\n","- $\\mathbb{E}[X] = 1 \\times p + 0 \\times (1 - p) = p$\n","- $V[X] = p(1-p)$\n","\n","### **3. Loi binomiale :**\n","On considère une expérience aléatoire qui ne possède que deux résultats : succès ($s$), échec ($\\overline{s}$). On pose :\n","- $p = P(s)$\n","- $q = P(\\overline{s}) = 1 - p$  \n","\n","On répète $n$ fois cette expérience, et on suppose que les répétitions sont indépendentes. On pose $X$ une variable aléatoire qui représente le nombre de succès au cours des $n$ répétitions, on dit alors que $X$ suit une loi binomiale de paramètre $n$ et $p$.  \n","La probabilité d'obtenir $k$ succès au cours de $n$ répétitions est noté :\n","$$P(X = k) = C^n_k \\times p^k(1 - p)^{n-k}$$  \n","\n","Où $C^n_k$, dit, $k$ parmis $n$, est le nombre de combinaisons de $k$ élements choisis parmi $n$.\n","$C$ est le coefficient binomial et est égale au nombre de chemins conduisant à strictement $k$ succès dans l'arbre représentant le schéma de Bernoulli. Plus formellement $C$ est définit comme suit :\n","$$C_k^n = \\frac{n!}{k!(n - k)!}$$\n","\n","*Note* Une expérience de Bernoulli est une loi Binomiale avec nombre de répétition $n = 1$. Une loi Binomiale est la répétition de $n$ fois le schéma de Bernoulli.\n","\n","#### Quelques propriété du coefficient Binomial\n","- $C_0^n = 1$, Nombre de chemin à 0 succès dans une suite de $n$ répétitions ? un seul chemin possible.\n","- De la même manière: $C_n^n = 1$.\n","- $C_1^n = n$, un seul succès sur $n$ répétitions: $n$ combinaisons possibles; $n=4 \\Longrightarrow (1000, 0100, 0010, 0001)$.\n","- Pour $0 \\leq k \\leq n$: $C^n_{n-k} = C^n_k$.\n","- Pour $0 \\leq k \\leq n$: $C^n_k + C^n_{k+1} = C^{n+1}_{k+1}$\n","- En utilisant les régles précédentes, on peut simplifier le calcul. **Exemple**\n","    - $C^4_2 = C^{3 + 1}_{1 + 1} = C^3_1 + C^3_2 = 3 + C^2_1 + C^2_2 = 3 + 2 +1 = 6$\n","\n","### **4. Loi de Bayes :**\n","Pour bien comprendre la loi de Bayes, il faut comprendre la notion de dépendance entre événements. Soit $A$ et $B$ deux événements :\n","- Si $A$ et $B$ sont indépendants, alors : \n","    - $P(A \\cap B) = P(A)P(B) = P(B)P(A) = P(B \\cap A)$  \n","    - $P(A | B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A)P(B)}{P(B)} = P(A)$\n","- Si $A$ et $B$ sont dépendants, alors : \n","    - $P(A \\cap B) = P(B)P(A|B) = P(A)P(B|A) = P(B \\cap A)$  \n","\n","$P(A \\cap B)$ est la probabilité de l'arrivée des événements $A$ et $B$. Dans le cas d'une dépendances entre ces dérniers, il faut alors prendre en considération l'ordre d'arrivé. Si $A$ est arrive en premier, la probabilité d'avoir $B$ lorsque $A$ est présent est définie par $P(B|A)$ ($B$ sachant $A$, et aussi noté $P_A(B)$). On aura donc $P(A \\cap B) = P(A) \\times P(B|A)$. Dans un deuxième cas où $B$ arrive en premier, on aura alors $P(B) \\times P(A|B)$.  \n","Par inférence, on a alors :\n","$$A \\cap B = B \\cap A \\Longleftrightarrow P(A \\cap B) = P(B \\cap A) \\Longleftrightarrow P(B)P(A|B) = P(A)P(B|A)$$  \n","Ce qui nous donne la loi de Bayes définit par :\n","$$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$  \n","Il est à noter aussi que dans un système d'événements complet $(\\Omega, A, P)$ où toutes les probabilités $P_i$ des événements $A_i$ sont non nulles. La loi de Bayes est définit par :\n","$$B = B \\cap A_1 + B \\cap A_2 + ... + B \\cap A_n = \\sum_{i \\in A} B \\cap A_i$$\n","$$P(B) = \\sum_{n \\geq 1} P(A_n) \\times P(B | A_n)$$  \n","Formule souvent utilisée quand le système est constitué de $A$ et $\\overline{A}$ :\n","$$P(A|B) = \\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\\overline{A})P(\\overline{A})}$$  \n","*Note* Attention, on se permet d'utiliser $\\overline{A}$ car on peut la déduire étant donné que le système n'est constitué que des deux événements contraires. Dans un systèmes avec plus d'événements, il faudra avoir plus d'informations sur les autres événements. De manière plus générale on notera :\n","$$P(A_k|B) = \\frac{P(B|A_k)P(A_k)}{P(B)} = \\frac{P(B|A_k)P(A_k)}{\\sum_{i \\geq 1}^n P(A_i)P(B |A_i)} \\;\\; avec \\;\\; k \\neq i$$  \n","\n","**Exemple pour avoir une meilleure idée**: Posons deux événements $A$ = \"tomber malade\" et $B$ = \"être testé positif\". La probabilité de tomber malade ($A$ arrive en premier) puis être testé positif ($B$ arrive en second) est assez élévée, soit par exemple $90\\%$, si on suppose que le test est de bonne qualité. Cependant, la probabilité d'être testé positif ($B$ arrive en premier) puis de tomber malade ($A$ arrive en second) est assez basse, il est moins probable de tomber malade en ayant déjà été testé positif.  \n","Soit $P(A) = 30\\%$ et $P(B|A) = 90\\%$, en utilisant les formules précédentes, il est possible de calculer $P(A|B)$:\n","- $P(B) = P(A)P(B|A) + P(\\overline{A})P(B|\\overline{A}) = 0,3 \\times 0,9 + 0,7 \\times 0,1 = 0,34$\n","- $P(A|B) = \\frac{P(A)P(B|A)}{P(B)} = \\frac{0,3 \\times 0,9}{0,34} = 0,79$\n","\n","## **Processus stochastique**\n","Un processus stochastique est une fonction du temps dont la valeur à chaque instant $t$ dépend de l'issue d'une expérience aléatoire.\n","- Le temps peut être discret ou continu.\n","- L'ensemble $E$ est l'ensemble des états possibles que peut prendre la variable $X^{(t)}$.  \n","### Vecteur et matrice stochastique :\n","- Un vecteur $\\pi = (\\pi_0, \\pi_1, \\pi_2, ..., \\pi_n)$ est stochastique seulement si la somme des composantes est égale à 1 : $\\sum_i^n \\pi_i = 1$.\n","- Pareil pour une matrice, chaque ligne est un vecteur stochastique.  \n","**Exemple**\n","$$\\pi = (\\frac{1}{4}, \\frac{1}{2}, \\frac{1}{4}); \\;\\;\\; P = \\begin{bmatrix}\\frac{1}{2} & \\frac{1}{2} & \\frac{1}{4} & = 1\\\\ \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} & = 1\\\\\\frac{1}{2} & 0 & \\frac{1}{2} & = 1\\\\ \\end{bmatrix}$$\n","\n","### Processus sans mémoire (Processus Markovien) :\n","Un processus Markovien est un processus ayant la propriété de Markov. L'évolution du processus ne dépend que du présent, c-à-dire qu'à un instant $t+1$, on ne dépend que de l'état à l'instant $t$ :\n","$$P[X_{n+1} = x_{n+1} | X_0=x_0; X_1=x_1; ...; X_n=x_n] = P[X_{n+1} = x_{x+1}|X_n=x_n]$$ \n","\n","## **Les chaînes de Markov**\n","### **1. Les chaînes de Markov à temps discret :**\n","$E$ est un espace d'états discrets, peut être fini ou dénombrable. ${X_n}_{n \\in E}$ est une variable aléatoire qui modélise une chaîne de Markov à temps discret (CMTD) seulement si :\n","$$P[X_n = j | X_{n - 1} = i_{n - 1}; X_{n - 2} = i_{n-2}; ...; X_0 = i_0] = P[X_j = j|X_{n - 1} = i_{n-1}]$$  \n","$X$ représente un processus sans mémoire.  \n","#### **Propriétés d'une CMTD :**\n","- On pose $P_{ij}$ la probabilité de transiter vers l'état $j$ sachant qu'à l'instant $t-1$ on etait à l'état $i$.\n","$$P_{ij} = P[X_n = j | X_{n-1}=i]; \\;\\; \\forall n \\in \\mathbb{N}$$\n","- On note aussi la somme des probabilités d'une transition d'un état $i$ vers $j$ est égale à 1: $\\sum_{j \\in E} P_{ij} = 1$.\n","- Il est possible de transiter vers le même état : $P_{ii} \\geq 0$.  \n","**Exemple**  \n","$E = \\{1, 2, 3, 4\\}$; $P = [P_{ij}]; i,j \\in E$\n","$$P = \\begin{bmatrix}0 & P_{12} & 0 & P_{14} & = 1 \\\\0 & 0 & 1 & 0 & =1 \\\\P_{31} & 0 & P_{33} & 0 & =1 \\\\1 & 0 & 0 & 0 & = 1 \\end{bmatrix}$$  \n","*Note* Peut être représenté sous la forme d'un graphe pondéré où les poids sont les probabilités de transition.\n","\n","#### **Distribution de l'état initial** :\n","- L'état initial est défini par le vecteur $\\pi^{(0)} = (\\pi^{(0)}_0, \\pi^{(0)}_1, \\pi^{(0)}_2, ..., \\pi^{(0)}_n)$ où $\\pi^{(0)}_i = P[X_0 = i]$ (Probabilité que la chaîne se trouve à l'état $i$ à l'instant $0$).  \n","- Si un système est initialement à l'état $j$ alors $\\pi^{(0)}_j = 1$ et $\\pi^{(0)}_i = 0$; $\\forall i \\neq j$.\n","\n","### **2. Analyse d'une chaîne de Markov à temps discret** :\n","#### **Régime transitoire :**\n","Afin de déterminer le vecteur $\\pi^{(n)}$ des probabilités d'états à un instant $n$, on pose :\n","- État du vecteur $n$ : $\\pi^{(n)} = [\\pi^{(n)}_j]_{j \\in E} = [\\pi^{(n)}_1, \\pi^{(n)}_2, \\pi^{(n)}_3, ..., \\pi^{(n)}_j]$.\n","- Les valeurs de transition dépendent de la matrice de transition $P$ :\n","$$\\pi^{(n)}_j = P[X_n = j] = \\sum_{i \\in E} P[X_{n - 1} = i] \\times P[X_n = j | X_{n - 1} = i] \\;\\; Loi \\;\\; de \\;\\; Bayes$$\n","$$\\pi^{(n)}_j = \\sum_{i \\in E} \\pi^{(n-1)}_j \\times P_{ij}$$  \n","Par récursion jusqu'à $0$, on obtient :\n","$$\\pi^{(n)}_j = \\pi^{(n-1)} \\times P = \\pi^{(0)}P^n$$  \n","**Explication**  \n","$P[X_n = j]$ est la probabilité d'être à l'état $n$ à l'instant $j$ et est noté $\\pi{(n)}_j$. Pour obtenir cette probabilité d'être à l'état $n$, il faut sommer toutes les probabilités de transition vers cette état en démarrant de l'état précédent $i$ (Il faut considérer tout les chemins possibles). Plus formellement cela donne $P[X_{n - 1} = i] \\times P[X_n = j | X_{n - 1} = i]$ pour un seul chemin, en sommant le tout on obtient $\\Longleftrightarrow \\sum_{i \\in E} P[X_{n - 1} = i] \\times P[X_n = j | X_{n - 1} = i]$.  \n","Pour encore mieux comprendre, il faut savoir que $P[X_n = i]$ est simplement la probabilité d'être à l'état $i$ qu'on note $\\pi$. quant à $P[X_n = i| X_{n - 1} = j]$, c'est la probabilité de **transiter** de l'état $j$ vers $i$ et qu'on note $P$ (C'est une matrice).  \n","Quant à la récursion jusu'à $0$, voici un déroulement pour mieux comprendre :\n","- $\\pi^{(1)} = \\pi^{(0)} \\times P$\n","- $\\pi^{(2)} = \\pi^{(1)} \\times P = \\pi^{(0)} \\times P^2$\n","- $\\pi^{(3)} = \\pi^{(2)} \\times P = \\pi^{(0)} \\times P^3$\n","- ...\n","- $\\pi^{(n)} = \\pi^{(0)} \\times P^n$ *Appellé formule de probabilités totales*\n","\n","#### **Évolution globale du processus $X_n$ ($m$ étapes) :**\n","Soit $P_{ij}^{(m)}$ la probabilité de transition de $i$ vers $j$ en $m$ étapes:\n","$$P_{ij}^{(m)} = P[X_{n+m} = j|X_n = i] = \\sum_{k \\in E} P_{ik}^{(m - 1)} \\times P_{kj}$$  \n","Cette probabilité est égale à $\\pi^{(m)}_j$ (L'état $j$ est à l'étape $m$). il faut donc sommer toutes les probabilités de transition vers cette état en démarrant de l'état précédent $i$ (Il faut considérer tout les chemins possibles). Plus formellement cela donne $P[X_{n + m - 1} = i] \\times P[X_{n + m} = j | X_{n + m - 1} = i]$ pour un seul chemin, en sommant le tout on obtient $\\Longleftrightarrow \\sum_{i \\in E} P[X_{n + m - 1} = i] \\times P[X_{n + m} = j | X_{n + m - 1} = i]$. Pour encore mieux comprendre, il faut savoir que $P[X_n = i]$ est simplement la probabilité d'être à l'état $i$ qu'on note $\\pi$. Quant à $P[X_n = i| X_{n - 1} = j]$, c'est la probabilité de **transiter** de l'état $j$ vers $i$ et qu'on note $P$ (C'est une matrice).\n","\n","#### **Temps de séjour :**\n","Le temps de séjoir en un état $i$ en $n$ étapes est le temps passé dans un état de la chaîne de Markov. Suivant une distribution géométrique (de paramètre $P_{jj}$ \\forall j \\in E), on peut définir la formule suivante :\n","$$P[T=k] = p^k \\times (1-p)$$\n","Avec $T$ est le temps de séjour compté en nombre d'étapes et $p$ la probabilité de quitter l'état courant. Dans le cas d'une CMTD avec plusieurs noeuds, on peut définir $p$ comme étant la somme des probabilités de transitions à partir de l'état courant (On transforme la chaîne en une chaîne de deux états seulement, l'état courant et le reste).  \n","\n","La formule peut être retrouvé par récursion :\n","- $P[T = 1] = 1 - p$  \n","- $P[T = 2] = p \\times (1 - p)$  \n","- $P[T = 3] = p^{2} \\times (1 - p)$  \n","- $...$  \n","- $P[T = k] = p^{k - 1} \\times (1 - p)$  \n","\n","#### **Temps de séjour moyenne:**\n","Le temps de séjour moyen d'un état $i$ est défini par l'espérance de la loi géométrique :\n","$$\\mathbb{E}[T] = \\frac{1}{p}$$\n","\n","#### **CMTD irréductible :**\n","Une CMTD est dites irréductible si et seulement si on peut atteindre n'importe quel état $j$ à partir de $i$ avec $i \\neq j$ et en un nombre fini d'étapes (c-à-d qu'il n'y a pas de boucle dans la chaîne, sinon ça peut engendrer une faible probabilité de boucler infiniment).  \n","$$\\forall i, j \\in E, \\exists m > 1 \\Longrightarrow P_{ij}^{(m)} \\neq 0$$  \n","Une chaînes **non** irréductible possède au moins une sous chaîne absorbante.  \n","\n","### **3. Classification des états d'une chaîne de Markov:**\n","#### 1. État périodique :\n","On peut définir un état $i$ comme périodique si et seulement si on peut revenir après un nombre d'étapes multiple de $k > 1$ (c-à-d qu'il y a une boucle dans la chaîne):\n","$$\\exists k> 1 \\;\\;tel \\;\\; que \\;\\; P_{ij}^{(m)} = 0 \\;\\; pour \\;\\; tout \\;\\; m \\in \\mathbb{N} \\;\\; et \\;\\; m \\% k \\neq 0$$\n","On dit alors que la période de l'état $i$ est le plus grand entier $k$ vérifiant la propriété. La période d'une CMTD est le PGCD des périodes de tout ses états. Si la période est égale à $1$, alors la CMTD est dite **apériodique**.  \n","#### 2. État transitoire et récurrent :\n","Avant tout il faut définir la probabilité $f_{jj}$ de transition de l'état $j$ vers l'état $j$ (c-à-d $P_{jj}^{(m)} = 1$). \n","- On peut définir un état $i$ comme transitoire si et seulement si $f_{ij}$ est supérieur à $f_{ji}$ (c-à-d $P_{ij}^{(m)} > P_{ji}^{(m)}$, il est plus probable d'y sortir que d'y entrer. Il est donc transitoire). \n","- On peut définir un état $i$ comme récurrent si et seulement si $f_{ij}$ est inférieur à $f_{ji}$ (c-à-d $P_{ij}^{(m)} < P_{ji}^{(m)}$, de la même manière, il est plus probable d'y entrer que d'y sotir. Il est donc récurrent).  \n","\n","Pour faire beaucoup plus simple, on définit les formule suivante :\n","$$f_{ij} = P_{ij}^{(m)} = \\sum_{m \\in \\mathbb{N}}^\\infty P_{ij}^{(m)}$$  \n","Un état est :\n","- **Transitoire** si et seulement si $f_{jj} < 1$\n","- **Récurrent** si et seulement si $f_{jj} = 1$. De plus :\n","    - Il est **récurrent nul** si le temps moyen de retour est infini. Noté $M_j = \\infty$ (M_j est le temps moyen de retour vers $j$).\n","    - Il est **récurrent non nul** si le temps moyen de retour est fini. Noté $M_j = \\sum_{n=1}^{\\infty} nf_{jj}^{(n)}$ (Revoir la formule de l'espérence d'une variable discrète pour comprendre l'origine de la formule).\n","\n","### **3. Ergodicité d'une chaîne de Markov:**\n","Une chaîne de Markov est dite **ergodique** si et seulement si elle est irréductible et que tous ses états sont transitoires (tout les états sont atteignables). Plus formellement, la chaîne est érgodique si $\\lim_{t \\rightarrow \\infty} \\pi^{(t)}$ existe est ne dépend pas du vecteur initial $\\pi^{(0)}$. En plus, une chaîne est :\n","- Irréductible si tout ses états sont de la même nature.\n","- Irréductible finie si tout ses états sont récurrents non nuls.\n","\n","#### Le nombre moyen de passage par un état\n","Soit $R_{ij}$ le nombre moyen de passages par un état $j$ sachant que l'on vient d'un état $i \\neq j$ :\n","$$R_{ij} = \\sum_{n=1}^{\\infty} n \\times P[Y=n_{passages} |X_{t-1}=i]$$\n","Avec $Y$ le nombre de passages $n$ par un état $j$ et $X_{t-1}$ l'état précédent. On note aussi :\n","$$R_{ij} = \\frac{f_{ij}}{1 - f_{jj}}$$\n","c-à-dire que $R_{ij}$ est égal à la probabilité de transition d'un état $i$ vers l'état $j$ (un passage de $j$) divisé par la probabilité de transition de tout les autres états sauf vers lui même (tout les chemins possibles sauf les boucles internes de $j$ vers $j$ car ce ne sont pas réellement des passages mais plutot une station sur le même état).\n","\n","### **4. Régime permanent:**\n","Il s'agit de l'étude d'un état stationnaire de $\\pi$ si ce dérnier existe. On peut définir un régime permanent comme un état stationnaire de $\\pi$ si et seulement si :\n","$$\\lim_{t \\rightarrow \\infty} \\pi^{(t)} = \\pi^{(0)}P^n \\Longrightarrow \\pi^{(n)} = \\pi^{(n+1)}$$\n","il faut donc résoudre le système d'equations suivant :\n","$$\\pi = \\pi P$$\n","\n","Cependant, il existe des condtions nécéssaires mais pas suffisantes pour qu'un régime permanent soit vrai. La chaîne de Markov doit être irréductible (donc apériodique), et les états doivent être transitoires (érgodique). On aura alors $\\lim_{n \\rightarrow \\infty} \\pi^{(n)} =\\pi^{(p)}$ existe et ne dépend pas du vecteur initial $\\pi^{(0)}$. \n","$$\\pi_j = \\sum_{i \\in E} \\pi_{i} P_{ij} = \\sum_{j} P_{ji} = \\pi P$$\n","Car les flux sortants sont égaux aux flux entrants, et de ce fait $\\sum_{i \\in E} P_{ij} = 1$.  \n","**Rappel** la formule suivante est très utile pour résoudre les systèmes d'équations :\n","$$\\sum_{i \\in E} \\pi_i = 1$$  \n","\n","Si la probabilité stationnaire existe, alors il existe un régime permanent et on note :\n","$$\\pi_i = \\frac{1}{M_i}$$"],"auto_number":1}],"metadata":{"interpreter":{"hash":"101b61497117ea3f18d4e0f8cf93eb2d64c16663f47aa00fa1289b89b66d7e41"},"kernelspec":{"display_name":"Python 3.6.12 64-bit ('deeplearning': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}},"__N_SSG":true}